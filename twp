#!/usr/bin/python3

# Imports for basic usage
import json
import sys
import math
import re
import numpy as np # pip3 install numpy
import matplotlib.pyplot as plt # pip3 install matplotlib
from PIL import Image # pip3 install pillow

# Use NTLK WordNet data to get word associations
def getTextData():

    # Dev imports
    import nltk # pip3 install nltk
    from nltk.corpus import wordnet as wn # pip3 install nltk
    from nltk.corpus import words # pip3 install nltk
    from nltk.corpus import stopwords # pip3 install nltk
    from nltk.corpus import names # pip3 install nltk
    from nltk.stem import WordNetLemmatizer # pip3 install nltk
    from nltk.stem import PorterStemmer
    import os.path

    # Load required NLTK data
    nltk.download('wordnet')
    nltk.download('words')
    nltk.download('stopwords')
    nltk.download('names')
    lemmatizer = WordNetLemmatizer()
    ps = PorterStemmer()

    # List of punctuation
    allowedPunc = ["\n", "_", "=", "+", "!", "?", ".", ",", ":", ";", "/", "\\", "\"", "*", "%", "$", "Â£", "&", "~", "(", ")", "{", "}", "]", "[", "@", "<", ">", "|", "`", "#", "-"]

    # Get stop words (words to ignore in definitions)
    stops = set(stopwords.words('english')) 
    stops.update(allowedPunc)

    # Create file if doesn't already exist
    if not os.path.isfile("data.json"):
        with open("data.json", "w") as f:
            f.write("{}")

    # Load the training data
    data = {}
    with open("data.json", "r") as f:
        data = json.load(f)

    # Load the word list
    words = set(words.words())
    words.update(set(wn.all_lemma_names()))
    print("Loaded " + str(len(words)) + " words from corpus data")

    # Load names
    nameList = set([])
    nameList.update(names.words('male.txt'))
    nameList.update(names.words('female.txt'))
    print("Loaded " + str(len(nameList)) + " names from corpus data")

    # Add names
    words.update(nameList)

    # Split genus_species into seperate words
    newWords = set([])
    toRem = set([])
    for word in words:
        if "_" in word:
            newWords.update(word.split("_"))
            toRem.add(word)

    # Remove the words to remove and add the new words
    words = words.difference(toRem)
    words.update(newWords)

    # If a is a word, add it as a form of b
    def tryWord(a, b):
        if len(wn.synsets(a)) > 0:
            data[a] = {"c": "", "s": [b]}

    # Regardless if a is a word, add it as a form of b
    def addWord(a, b):
        data[a] = {"c": "", "s": [b]}

    # For each word
    for word in words:

        # Remove newlines
        word = word.strip()

        # Ignore empty lines
        if len(word) > 0:

            # Create empty set (only allowing unique words)
            syns = set({})

            # Get all the WordNet synonyms
            for index, ss in enumerate(wn.synsets(word)):

                # Get the root words of the synonyms
                lemmas = set(ss.lemma_names())

                # Remove any hyphenated words and make lowercase
                stripped = stripWords([x for x in lemmas if x != "null"], allowedPunc)

                # Add to the set for this word
                syns.update(stripped)

                # Get the word itself
                for w in stripped:
                    if w == word:

                        # Add words from word description 
                        description = stripWords(ss.definition().split(), stops)

                        # Add to the set for this word
                        syns.update(description)

            # Force key to also be lowercase
            word = word.lower()

            # Also add the plural
            addWord(word+"s", word)

            # become -> became
            if word[-4:] == "come":
                tryWord(word[:-4]+"came", word)

            # begin -> began
            elif word[-3:] == "gin":
                tryWord(word[:-3]+"gan", word)

            # woman -> women
            elif word[-3:] == "man":
                tryWord(word[:-3]+"men", word)

            # draw -> drew
            elif word[-4:] == "draw":
                tryWord(word[:-4]+"drew", word)

            # For words ending in e, try various endings and add if valid
            elif word[-1] == "e":
                tryWord(word[:-1]+"ed", word)
                tryWord(word[:-1]+"ing", word)
                tryWord(word[:-1]+"or", word)
                tryWord(word[:-1]+"est", word)
                tryWord(word[:-1]+"er", word)
                tryWord(word[:-1]+"est", word)

            # For words ending in y, try various endings and add if valid
            elif word[-1] == "y":
                tryWord(word[:-1]+"iest", word)
                tryWord(word[:-1]+"ies", word)
                tryWord(word[:-1]+"ied", word)
                tryWord(word+"ing", word)

            # For all other words
            else:
                tryWord(word+"iest", word)
                tryWord(word+"ing", word)
                tryWord(word+word[-1]+"ed", word)
                tryWord(word+"ed", word)
                tryWord(word+"er", word)
                tryWord(word+"es", word)
                tryWord(word+"est", word)

            # Add the element if not already present
            if word not in data.keys(): data[word] = {"c": "", "s": []}

            # Update the similar list
            data[word]["s"] = list(syns)

    # No easy way to do all the contractions so just add them manually
    addWord("etc", "etcetera")
    addWord("cannot", "can")
    addWord("don't", "do")
    addWord("can't", "can")
    addWord("won't", "will")
    addWord("shouldn't", "should")
    addWord("shan't", "should")

    # Rather than saving everything + "'s", just split it off
    addWord("'s", "plural")

    # Add various pieces of punctation
    for punc in allowedPunc:
        addWord(punc, "punctuation")

    # Add blank space
    addWord(" ", "punctuation")

    # Useful info showing roughly how long things'll take 
    print("Total words in data set: " + str(len(data.keys())))

    # Save the data again
    with open("data.json", "w") as f:
        json.dump(data, f, separators=(',', ':'))
        f.write("\n")

# Download colour data from cymbolism.com, also matplotlibs xkcd/css values
def getImageData():

    # Dev imports
    import urllib.request
    import re
    import time
    import matplotlib._color_data as mcd # pip3 install matplotlib
    import matplotlib.colors # pip3 install matplotlib
    import os.path

    # A site where people vote on what colour they associate with a word
    baseURL = "http://cymbolism.com/words"

    # Seconds to wait between requests
    waitTime = 2

    # Create file if doesn't already exist
    if not os.path.isfile("data.json"):
        with open("data.json", "w") as f:
            f.write("{}")

    # Load the training data
    data = {}
    with open("data.json", "r") as f:
        data = json.load(f)

    # For each css colour
    for color in mcd.CSS4_COLORS:

        # Get the actual colour in tuple form
        col = matplotlib.colors.to_hex(color)

        # Ensure it's a valid word
        if color in data.keys():

            # If this word doesn't already have an ideal colour
            if len(data[color]["c"]) <= 0:
                data[color]["c"] = col

    # For each xkcd color (only procesing single word names)
    for color in mcd.XKCD_COLORS:

        # Split into words
        splitNames = color[5:].replace("liliac", "lilac").split()

        # Get the actual colour in tuple form
        col = matplotlib.colors.to_hex(color)

        # For now only do single word colours
        if len(splitNames) == 1:
            
            # Ensure it's a valid word
            if splitNames[0] in data.keys():

                # If this word doesn't already have an ideal colour
                if len(data[splitNames[0]]["c"]) <= 0:
                    data[splitNames[0]]["c"] = col

    # For each xkcd color (this time for more complex names)
    for color in mcd.XKCD_COLORS:

        # Split into words
        splitNames = color[5:].replace("liliac", "lilac").split()

        # Get the actual colour in tuple form
        col = matplotlib.colors.to_hex(color)

        # Now do multiple word colours e.g. charcoal grey
        if len(splitNames) > 1:
            
            # Loop over the names
            for name in splitNames:

                # Ensure it's a valid word
                if name in data.keys() and name not in ["pale", "light", "dark"]:

                    # If this word doesn't already have an ideal colour
                    if len(data[name]["c"]) <= 0:
                        data[name]["c"] = col

    # Get the base page containing all the different links
    basePage = urllib.request.urlopen(baseURL)
    baseHTML = basePage.read().decode("utf8")
    basePage.close()

    # Find all the links
    links = re.findall('href="http://cymbolism\\.com/words/.+?"', baseHTML)
    print("Loading " + str(len(links)) + " ideal colours")
    print("This'll take about " + str(waitTime*len(links)) + " seconds (" + str(round(waitTime*len(links)/60.0)) + " minutes)")

    # For each link
    for link in links:

        # Get the page
        linkPage = urllib.request.urlopen(link[6:-1])
        linkHTML = linkPage.read().decode("utf8")
        linkPage.close()

        # Extract the color and word
        colorURL = re.search('href="http://cymbolism\\.com/colors/.+?"', linkHTML)[0]
        color = colorURL[-7:-1]
        wordsText = link[link.rfind("/")+1:-1]

        # Split "art%20deco" into ["art", "deco"]
        words = wordsText.replace("%20", " ").lower().split()

        # Treat each split word equally
        for word in words:

            # Add the element if not already present
            if word not in data.keys(): data[word] = {"c": "", "s": []}

            # Update the colour
            data[word]["c"] = color

        # Don't overload the servers
        time.sleep(waitTime)

    # Save the data again
    with open("data.json", "w") as f:
        json.dump(data, f, separators=(',', ':'))
        f.write("\n")

# Using data.json, create and optimise map.json 
def optimiseMapping():

    # Dev imports 
    import random
    import os.path

    # Create colour space array mapping colors -> indices
    colourSpace = np.zeros((256, 256, 256)) - 1

    # Load optimisation data
    data = {}
    with open("data.json", "r") as f:
        data = json.load(f)

    # Get the mapping from indices -> words
    wordIndices = list(data.keys())

    # Seed rng
    random.seed("twp")

    # Keep track of how many colour mappings are known
    positionsKnown = 0

    # If a mapping exists already
    if os.path.isfile("map.json") and False: # False is for debugging

        # Load it
        mapping = loadMapping()

        # Populate colour space
        for index, word in enumerate(wordIndices):

            # If the word has a colour mapping saved
            if word in mapping.keys():
                r, g, b = mapping[word]
                colourSpace[r, g, b] = index
                data[word]["added"] = True
                positionsKnown += 1

            # If it doesn't, note it
            else:
                data[word]["added"] = False

    # If mapping doesn't exist
    else:

        # Create a blank mapping, noting that all words known need to be added
        mapping = {}
        for word in wordIndices:
            data[word]["added"] = False

    # For each pass of words with an ideal colour
    passesKnown = 20
    for i in range(passesKnown):

        # For each word in data
        for index, word in enumerate(wordIndices):

            # If not added already
            if not data[word]["added"] and len(data[word]["c"]) > 0:

                # Convert the hex colour to a col tuple
                r, g, b = hexToCol(data[word]["c"])

                # Attempt to place it there
                if colourSpace[r, g, b] == -1:
                    colourSpace[r, g, b] = index
                    data[word]["added"] = True
                    mapping[word] = (r, g, b)

                # If failed
                else:

                    # Generate random displacement
                    dr = random.randint(-5, 5)
                    dg = random.randint(-5, 5)
                    db = random.randint(-5, 5)

                    # Limit to valid range
                    r = max(min(r + dr, 255), 0)
                    g = max(min(g + dg, 255), 0)
                    b = max(min(b + db, 255), 0)

                    # Attempt to place
                    if colourSpace[r, g, b] == -1:
                        colourSpace[r, g, b] = index
                        mapping[word] = (r, g, b)
                        data[word]["added"] = True

    print("Initial ideal mappings for " + str(len(mapping.keys())) + " / " + str(len(data.keys())) + " words")

    # For each pass over the words that don't have an ideal colour
    passesUnknown = 20
    for i in range(passesUnknown):

        # For each word in data
        for index, word in enumerate(wordIndices):

            # If not added already
            if not data[word]["added"]:

                # For each similiar word
                for syn in data[word]["s"]:

                    # If the similiar word has been placed
                    if syn in mapping.keys():
                        if data[syn]["added"]:

                            # Get the location placed
                            r, g, b = mapping[syn]

                            # Generate random displacement
                            dr = random.randint(-5, 5)
                            dg = random.randint(-5, 5)
                            db = random.randint(-5, 5)

                            # Limit to valid range
                            r = max(min(r + dr, 255), 0)
                            g = max(min(g + dg, 255), 0)
                            b = max(min(b + db, 255), 0)

                            # Attempt to place
                            if colourSpace[r, g, b] == -1:
                                colourSpace[r, g, b] = index
                                data[word]["added"] = True
                                mapping[word] = (r, g, b)
                                break

    print("Initial similarity mappings for " + str(len(mapping.keys())) + " / " + str(len(data.keys())) + " words")

    # Any word not assigned, give it a random unique colour 
    maxGuesses = 1000
    for index, word in enumerate(wordIndices):

        # If not added already
        if not data[word]["added"]:

            # Put a (high) max limit just in case
            for i in range(maxGuesses):

                # Generate random position
                r = random.randint(0, 255)
                g = random.randint(0, 255)
                b = random.randint(0, 255)

                # Attempt to place
                if colourSpace[r, g, b] == -1:
                    colourSpace[r, g, b] = index
                    data[word]["added"] = True
                    mapping[word] = (r, g, b)
                    break

    print("Total initial mappings for " + str(len(mapping.keys())) + " / " + str(len(data.keys())) + " words")

    # For each iteration 
    maxOptPasses = 300
    saveEvery = 20
    avg = 0
    totalDistance = 0
    numWords = len(mapping.keys())
    for i in range(maxOptPasses):

        # For each word
        for word in list(mapping.keys()):

            # Get the current colour location
            r, g, b = mapping[word]
            newR, newG, newB = (r, g, b)
            
            # If it has an ideal colour
            if len(data[word]["c"]) > 0:

                # Usually pick this colour to move towards
                if random.randint(0, 10) <= 8 or len(data[word]["s"]) == 0:

                    newR, newG, newB = hexToCol(data[word]["c"])

                # Occasionally pick a random similar word to move towards
                else:

                    ran = random.randint(0, len(data[word]["s"])-1)
                    targetWord = data[word]["s"][ran]
                    if targetWord in mapping.keys():
                        newR, newG, newB = mapping[targetWord]

            # If it doesn't
            elif len(data[word]["s"]) > 0:

                # Pick a random similiar word to move towards
                ran = random.randint(0, len(data[word]["s"])-1)
                targetWord = data[word]["s"][ran]
                if targetWord in mapping.keys():
                    newR, newG, newB = mapping[targetWord]

            # Determine the delta to head towards the new location
            deltaR = newR - r
            deltaG = newG - g
            deltaB = newB - b

            # Normalise
            total = max(math.sqrt(deltaR**2 + deltaG**2 + deltaB**2), 1)
            deltaRNorm = round(deltaR / total)
            deltaGNorm = round(deltaG / total)
            deltaBNorm = round(deltaB / total)

            # Update the total total
            totalDistance += total

            # Position to swap with
            swapR = r + deltaRNorm
            swapG = g + deltaGNorm
            swapB = b + deltaBNorm
            
            # Swap towards this colour location if, only swap if empty
            temp = colourSpace[swapR, swapG, swapB]
            colourSpace[swapR, swapG, swapB] = colourSpace[r, g, b]
            colourSpace[r, g, b] = temp
            mapping[word] = (swapR, swapG, swapB)
            if temp != -1:
                mapping[wordIndices[int(temp)]] = (r, g, b)

        # Determine the average distance to the target
        avg = totalDistance / float(numWords)

        # Every so often, save the mapping and output
        if i % saveEvery == 0: 
            saveMapping(mapping)
            print("Opt pass " + str(i+1) + ", averaging " + str(avg))

        # Sum the total distance to the target for averaging
        totalDistance = 0

# Strip various chars from words 
def stripWords(words, stops=set([])):

    # List of allowed punctuation
    allowedPunc = ["\n", "_", "=", "+", "!", "?", ".", ",", ":", ";", "/", "\\", "\"", "*", "%", "$", "Â£", "&", "~", "(", ")", "{", "}", "]", "[", "@", "<", ">", "|", "`", "#", "-"]

    # Iterate over the words
    newWords = []
    for word in words:

        # Lowercase 
        preSplit = word.lower()
        toAdd = []

        # Replace certain weird chars with normal versions
        preSplit = preSplit.replace("â", "\"").replace("â", "\"").replace("â", "'").replace("â", "'").replace("â", "-")

        # Allow some punctuation and treat it seperately e.g. "#test?" -> ["#", "test", "?"]
        for punc in allowedPunc:
            preSplit = preSplit.replace(punc, " " + punc + " ")

        # Split off "'s"
        preSplit = preSplit.replace("'s", " 's ")

        # Remove numbers
        preSplit = ''.join([c for c in preSplit if not c.isdigit()])

        # Remove leading '
        if len(preSplit) > 0:
            if preSplit[0] == "'":
                preSplit = preSplit[1:]

        # Remove trailing '
        if len(preSplit) > 0:
            if preSplit[-1] == "'" and preSplit[-2] != "s":
                preSplit = preSplit[:-1]

        # Split hypen-ated and under_scored words into their components
        toAdd = preSplit.split(" ")

        # Check for non-zero length before adding
        for newWord in toAdd:
            if len(newWord) > 0:
                if len(stops) == 0 or newWord not in stops:
                    newWords.append(newWord)

    return newWords

# Plot an array of colours, to a file if saveInstead
def plotCols(cols, saveInstead, endCol, width=-1, height=-1, outputFile="output.png"):

    # Initial guess at best dimensions if not specified
    total = len(cols)
    if width == -1:
        width = math.ceil(math.sqrt(total))
    if height == -1:
        height = math.ceil(total / width)

    # Add extra colours to make it up if not rectangular
    for i in range(width*height - total):
        cols.append(endCol)

    # Convert to numpy data
    data = np.array(cols, dtype='uint8').reshape((height, width, 3))

    # Either show or save
    if saveInstead:
        fig = plt.figure(figsize=(width/100, height/100), dpi=100)
        ax = plt.axes([0,0,1,1])
        ax.set_axis_off()
        fig.add_axes(ax)
        plt.imshow(data, interpolation="none")
        plt.savefig(outputFile, bbox_inches=0, pad_inches=0)
    else:
        fig = plt.figure()
        ax = plt.axes([0,0,1,1])
        ax.set_axis_off()
        fig.add_axes(ax)
        plt.imshow(data, interpolation="none")
        plt.show()

# Load a mapping from a file
def loadMapping(mapFile="map.json", convertFromHex=True):

    # Load from file
    loaded = {}
    with open(mapFile, "r") as f:
        loaded = json.load(f)

    # Convert hexes to tuples 
    mapping = {}
    for key, value in loaded.items():
        if convertFromHex:
            mapping[key] = hexToCol(value)
        else:
            mapping[key] = value

    return mapping

# Write a mapping to a file
def saveMapping(mapping, mapFile="map.json", convertToHex=True):

    # Convert tuples to hexes
    toSave = {}
    for key, value in mapping.items():
        if convertToHex:
            toSave[key] = colToHex(value)
        else:
            toSave[key] = value

    # Save to file
    with open(mapFile, "w") as f:
        json.dump(toSave, f, separators=(',', ':'))
        f.write("\n")

# Use a mapping to get the colours for a set of words
def useMapping(mapping, wordsToConvert, verbose=False):

    # Loop over the words
    outputColours = []
    numUnknown = 0
    unknownWords = set([])
    for word in wordsToConvert:

        # If the word is known, get the colour from the dict
        if word in mapping.keys():
            outputColours.append(mapping[word])

        # If the word isn't known, use whatever "unknown" is mapped to
        else:
            numUnknown += 1
            unknownWords.add(word)
            outputColours.append(mapping["unknown"])

    # Output how many unknown words there were, if any
    if numUnknown > 0:
        print("Didn't know " + str(numUnknown) + " / " + str(len(wordsToConvert)) + " words (" + str(len(unknownWords)) + " unique)")
        if verbose:
            print(unknownWords)

    return outputColours

# Convert a colour hex to a color tuple, e.g. #ff0000 -> (255, 0, 0)
def hexToCol(hexVal):
    return (int(hexVal[1:3], 16), int(hexVal[3:5], 16), int(hexVal[5:7], 16))

# Convert a colour tuple to a color hex, e.g. (255, 0, 0) -> ff0000
def colToHex(colVal):
    return '#%02x%02x%02x' % colVal

def printHelp():

    print("TWP - Thousand Word Picture")
    print("")
    print("Description:")
    print(" Converts words into colours.")
    print(" This uses a one-to-one mapping optimised to")
    print(" group similiar words together and have the")
    print(" colours represent the words as best as possible.")
    print(" See https://github.com/lumorti/twp for details.")
    print("")
    print("Usage to convert text file to png:")
    print(" ./twp [flags?] [inputFile] [outputFile]")
    print("")
    print("Usage to convert png back to text file:")
    print(" ./twp -i [flags?] [inputFile] [outputFile]")
    print("")
    print("Usage to convert words and then display:")
    print(" ./twp -w [flags?] [words]")
    print("")
    print("General Flags:")
    print(" --words  -w         use the given words rather than a file")
    print(" --invert -i         convert colours to text instead")
    print(" --width  -x [int]   force the output image width in pixels")
    print(" --height -y [int]   force the output image height in pixels")
    print(" --near   -n [word]  list words near a word in colour space")
    print(" --help   -h         output this message")

if __name__ == "__main__":

    # Param defaults
    action = "help"
    inputFile = ""
    outputFile = ""
    inputMode = "file"
    outputMode = "save"
    mapFile = "map.json"
    verbose = False
    width = -1
    height = -1

    # The words/files to process
    wordArgs = []

    # Loop over the arguments given
    ind = 1
    while ind < len(sys.argv):
        arg = sys.argv[ind]

        # Process the argument
        if arg in ["--help", "-h"]:
            action = "help"
        elif arg in ["--text", "-t"]:
            outputMode = "text"
        elif arg in ["--near", "-n"]:
            action = "near"
        elif arg in ["--words", "-w"]:
            inputMode = "words"
            outputMode = "disp"
        elif arg in ["--verb", "-v"]:
            verbose = True
        elif arg in ["-5"]:
            inputMode = "guten"
            action = "use"
        elif arg in ["--invert", "-i"]:
            action = "invert"
        elif arg in ["--width", "-x"]:
            try:
                width = int(sys.argv[ind+1])
                ind += 1
            except:
                print("ERROR - not a valid width")
                exit()
        elif arg in ["--height", "-y"]:
            try:
                height = int(sys.argv[ind+1])
                ind += 1
            except:
                print("ERROR - not a valid width")
                exit()
        elif arg in ["-1"]:
            action = "1"
        elif arg in ["-2"]:
            action = "2"
        elif arg in ["-3"]:
            action = "3"
        elif arg in ["-4"]:
            action = "4"
        elif arg in ["-c", "--check"]:
            action = "c"

        # Otherwise it's either a word list or a filename
        else:
            wordArgs.append(arg)
            if action == "help": action = "use"

        # Easier than for loop since occasionally need to skip
        ind += 1

    # Get the input/output files
    if len(inputFile) == 0 and len(wordArgs) >= 1:
        inputFile = wordArgs[0]
    if len(outputFile) == 0 and len(wordArgs) >= 2:
        outputFile = wordArgs[1]

    # If asking for help
    if action == "help":
        printHelp()

    # Normal usage
    elif action == "use":

        # Ensure files are specified
        if inputMode == "file" and (len(inputFile) == 0 or len(outputFile) == 0):
            print("ERROR - please specify both the input and output files")
            exit()

        # Load the mapping
        mapping = loadMapping(mapFile)

        # If using files
        if inputMode == "file":
            with open(inputFile) as f:
                wordsToConvert = re.findall(r'\S+|\n', f.read())

        # If using quoted words
        elif inputMode == "words":
            wordsToConvert = wordArgs

        # If told to use a public domain book
        elif inputMode == "guten":
            from nltk.corpus import gutenberg
            wordsToConvert = gutenberg.words('austen-emma.txt')
            outputFile = "output.png"

        # Get rid of certain characters, force lowercase, split hyphons etc.
        wordsToConvert = stripWords(wordsToConvert)

        # Ensure there are some words
        if len(wordsToConvert) >= 1:

            # Use the mapping
            outputCols = useMapping(mapping, wordsToConvert, verbose)

            # Colour to use filling at the end
            endCol = mapping[" "]

            # Output the resulting colours as text
            if outputMode == "text":
                outputText = ""
                for index, word in enumerate(wordsToConvert):
                    outputText += colToHex(outputCols[index]) + "\n"
                with open(outputFile, "w") as f:
                    f.write(outputText)

            # Output the resulting colours as an image to the screen
            elif outputMode == "disp":
                plotCols(outputCols, False, endCol, width, height, outputFile)

            # Output the resulting colours as an image to a file
            elif outputMode == "save":
                plotCols(outputCols, True, endCol, width, height, outputFile)

        # If no words given (e.g. empty file or ./twp "")
        else:
            print("ERROR - you forgot to give any words to convert")
            exit()

    # Add synonyms to data file
    elif action == "1":

        getTextData()

    # Add colours to data file
    elif action == "2":

        getImageData()

    # Optimising an existing mapping
    elif action == "3":

        optimiseMapping()

    # Generate the inverse mapping 
    elif action == "4":

        # Load the mapping without converting hexes
        mapping = loadMapping(convertFromHex=False)
    
        # Create the blank colour -> word mapping
        inverse = {}

        # For each word
        for word in mapping.keys():

            # Add this colour as a key
            inverse[mapping[word]] = word

        # Save this new inverse mapping
        saveMapping(inverse, "inverse.json", False)

    # Return the object for a given word from data.json
    elif action == "c":

        # Load the data
        data = {}
        with open("data.json", "r") as f:
            data = json.load(f)

        # Return the object for the first word given
        try:
            print(data[inputFile])
        except:
            print("ERROR - word not in mapping, would you find it in a dictionary?")

    # Convert from an image/text containing colours back to words 
    elif action == "invert":

        # Load the inverse mapping
        inverse = loadMapping("inverse.json", convertFromHex=False)

        # If using files
        if inputMode == "file":

            # Load the pixels from the image using pillow
            pixels = np.array(Image.open(inputFile)).reshape(-1, 4)
            colsToConvert = []
            for pixel in pixels:
                colsToConvert.append(colToHex(tuple(pixel)[:-1]))

        # If using quoted colors
        elif inputMode == "words":
            colsToConvert = wordArgs

        # Convert the colors using the inverse mapping
        outputWords = []
        for col in colsToConvert:
            outputWords.append(inverse[col])

        outputText = " ".join(outputWords)
        outputText = outputText.replace(" \n ", "\n")
        outputText = outputText.strip() + "\n"

        # Output the text to the file
        with open(outputFile, "w") as f:
            f.write(outputText)

    # List some words with similiar colours
    elif action == "near":

        # Ensure a word is actually given
        if len(inputFile) == 0:
            print("ERROR - please specify a word")
            exit()

        # Load both mappings
        mapping = loadMapping()
        inverse = loadMapping("inverse.json", convertFromHex=False)

        # The word to search around
        word = inputFile

        # Get the col for this word
        r, g, b = mapping[word]
        ogHex = colToHex((r,g,b))

        # How many words to get
        maxRadius = 3
        triesPerRadius = 100

        # The text to output
        outputMap = {}
        outputText = "Nearby to " + word + " (" + ogHex + "): "

        # Ensure repeatability
        random.seed("twp")

        # Find nearer words first
        for radius in range(maxRadius):

            # Try multiple times due to the randomness
            for tryNum in range(triesPerRadius):

                # Get random nearby coordinates
                newR = min(max(r + random.randint(-radius, radius), 0), 255)
                newG = min(max(g + random.randint(-radius, radius), 0), 255)
                newB = min(max(b + random.randint(-radius, radius), 0), 255)

                # Convert this tuple to a hex colour
                newHex = colToHex((newR, newG, newB)) 

                # Get the word from the hex using the inverse mapping
                if newHex in inverse.keys() and newHex != ogHex:
                    outputMap[inverse[newHex]] = newHex

        # Add to the output text for each found nearby colour
        for key, value in outputMap.items():
            outputText += key + " (" + value + "), "

        # Strip the trailing comma
        outputText = outputText[:-2]

        # Output the nearby words
        print(outputText)

